{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3b1bde-23bc-4bb4-a620-7e4aa9c01fdc",
   "metadata": {},
   "source": [
    "# Importación de dependencias y lectura de datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d56c34-eefd-46fa-8d97-e9cac68a5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Dataset Oracle-RedBull\n",
    "races_info = pd.read_csv('final_data_spanish.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77349f-8f51-4c7c-8ffb-1bf495fc91cf",
   "metadata": {},
   "source": [
    "# Definición de variables de entrada y salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89ac7b-0a2d-4347-a595-69f1dc86a9d3",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0dbdc-8482-4b51-90ea-6d9c81fd1f93",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'eventYear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m races_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStint\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],  \u001b[38;5;66;03m# Ejemplo de stints\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlapNumberAtBeginingOfStint\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m60\u001b[39m],  \u001b[38;5;66;03m# Vueltas de inicio del stint\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHard\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Tipo de neumático\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesignedLaps\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m70\u001b[39m]  \u001b[38;5;66;03m# Vueltas totales de la carrera\u001b[39;00m\n\u001b[0;32m      6\u001b[0m })\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Crear `num_stops` calculando el número de stints únicos por carrera/piloto\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m races_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_stops\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mraces_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meventYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDriver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStint\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Crear columnas para vueltas de parada\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, races_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_stops\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\naxo_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naxo_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\naxo_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'eventYear'"
     ]
    }
   ],
   "source": [
    "races_info = pd.DataFrame({\n",
    "    'Stint': [1, 2, 1, 2, 3],  # Ejemplo de stints\n",
    "    'lapNumberAtBeginingOfStint': [10, 30, 15, 40, 60],  # Vueltas de inicio del stint\n",
    "    'Compound': ['Soft', 'Medium', 'Soft', 'Hard', 'Medium'],  # Tipo de neumático\n",
    "    'designedLaps': [70, 70, 70, 70, 70]  # Vueltas totales de la carrera\n",
    "})\n",
    "\n",
    "# Crear `num_stops` calculando el número de stints únicos por carrera/piloto\n",
    "races_info['num_stops'] = races_info_ds.groupby(['eventYear', 'Driver'])['Stint'].transform('max')\n",
    "\n",
    "# Crear columnas para vueltas de parada\n",
    "for i in range(1, races_info['num_stops'].max() + 1):\n",
    "    races_info[f'lap_stop_{i}'] = races_info.apply(\n",
    "        lambda row: row['lapNumberAtBeginingOfStint'] if row['Stint'] == i else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "# Crear columnas para tipos de neumático en cada parada\n",
    "for i in range(1, races_info['num_stops'].max() + 1):\n",
    "    races_info[f'tire_type_{i}'] = races_info.apply(\n",
    "        lambda row: row['Compound'] if row['Stint'] == i else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "# Llenar los NaN con valores específicos para mantener consistencia de datos\n",
    "races_info = races_info.fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19f632-7e10-47ba-a77b-3cf97a59d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de numeric_input: (286, 8)\n",
      "Forma de encoded_input: (286, 79)\n"
     ]
    }
   ],
   "source": [
    "# Codificar variables categóricas de entrada\n",
    "\n",
    "categorical_cols_input = ['EventName', 'Team', 'Driver', 'Rainfall']\n",
    "encoder_input = OneHotEncoder(sparse_output=False)\n",
    "encoded_input = encoder_input.fit_transform(races_info[categorical_cols_input])\n",
    "\n",
    "# Variables numéricas de entrada\n",
    "numeric_cols_input = ['RoundNumber', 'eventYear', 'meanAirTemp', 'meanTrackTemp',\n",
    "                      'meanHumid', 'GridPosition', 'CircuitLength', 'designedLaps']\n",
    "numeric_input = races_info[numeric_cols_input].values\n",
    "print('Forma de numeric_input:', numeric_input.shape)\n",
    "print('Forma de encoded_input:', encoded_input.shape)\n",
    "# Combinar y escalar\n",
    "X = np.hstack((numeric_input, encoded_input))\n",
    "scaler_input = MinMaxScaler()\n",
    "X = scaler_input.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbacb4-dbec-4b17-9984-c4ede3e7c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar vueltas de parada\n",
    "scaler_lap_stops = MinMaxScaler(feature_range=(0, 1))\n",
    "lap_stop_cols = [f'lap_stop_{i}' for i in range(1, races_info['num_stops'].max() + 1)]\n",
    "races_info[lap_stop_cols] = scaler_lap_stops.fit_transform(races_info[lap_stop_cols])\n",
    "\n",
    "# Codificar tipos de neumático\n",
    "tire_type_cols = [f'tire_type_{i}' for i in range(1, races_info['num_stops'].max() + 1)]\n",
    "encoder_tire_types = OneHotEncoder(sparse_output=False)\n",
    "tire_types_encoded = encoder_tire_types.fit_transform(races_info[tire_type_cols])\n",
    "\n",
    "# Combinar todas las columnas en un solo array de salida `y`\n",
    "y = np.hstack([races_info[lap_stop_cols].values, tire_types_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756e267-79f9-4bca-8279-6e5e74fa6aee",
   "metadata": {},
   "source": [
    "# Arquitectura CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac557e6-fda0-403e-9a62-96b3ad190ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_dim = X.shape[1]\n",
    "num_output_dim = 2 # Número de variables numéricas de salida\n",
    "cat_output_dim = tire_types_encoded.shape[1]  # Número de categorías de 'Compound'\n",
    "strategy_dim = num_output_dim + cat_output_dim\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bc357-43fc-4737-b88f-7cca89c2e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(noise_dim, condition_dim, max_stops=3, num_tire_types=3):\n",
    "    noise_input = Input(shape=(noise_dim,))\n",
    "    condition_input = Input(shape=(condition_dim,))\n",
    "    merged = Concatenate()([noise_input, condition_input])\n",
    "\n",
    "    x = Dense(128)(merged)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    # Salida para el número de paradas (1 a max_stops)\n",
    "    num_stops_output = Dense(max_stops, activation='softmax')(x)  # Predice el número de paradas como una categoría\n",
    "\n",
    "    # Salida para la vuelta de cada parada\n",
    "    lap_stop_outputs = []\n",
    "    for _ in range(max_stops):\n",
    "        lap_stop = Dense(1, activation='sigmoid')(x)  # Escalar entre 0 y 1\n",
    "        lap_stop_outputs.append(lap_stop)\n",
    "\n",
    "    # Concatenar todas las vueltas de parada y escalar al rango de vueltas\n",
    "    lap_stop_outputs = Concatenate()(lap_stop_outputs)\n",
    "    lap_stop_outputs_scaled = lap_stop_outputs * (condition_input[:, -1:] - 1) + 1  # Escalar entre [1, designedLaps]\n",
    "\n",
    "    # Salida para el tipo de neumático en cada parada\n",
    "    tire_type_outputs = []\n",
    "    for _ in range(max_stops):\n",
    "        tire_type = Dense(num_tire_types, activation='softmax')(x)  # Predice el tipo de neumático en cada parada\n",
    "        tire_type_outputs.append(tire_type)\n",
    "\n",
    "    # Concatenar todas las salidas\n",
    "    output = Concatenate()([num_stops_output, lap_stop_outputs_scaled] + tire_type_outputs)\n",
    "\n",
    "    model = Model([noise_input, condition_input], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addc0b2-e1fb-407e-9885-ed5929909cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminador\n",
    "def build_discriminator(strategy_dim, condition_dim):\n",
    "    strategy_input = Input(shape=(strategy_dim,))\n",
    "    condition_input = Input(shape=(condition_dim,))\n",
    "    merged = Concatenate()([strategy_input, condition_input])\n",
    "\n",
    "    x = Dense(256)(merged)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model([strategy_input, condition_input], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a700e82-3617-4746-bf3e-733e50b599d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar modelos\n",
    "# Crear el discriminador entrenable y compilarlo\n",
    "discriminator = build_discriminator(strategy_dim, condition_dim)\n",
    "optimizer_d = Adam(0.0002, 0.5)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer_d, metrics=['accuracy'])\n",
    "\n",
    "# Crear una copia del discriminador para usarla como no entrenable en el modelo combinado\n",
    "discriminator_non_trainable = clone_model(discriminator)\n",
    "discriminator_non_trainable.set_weights(discriminator.get_weights())\n",
    "discriminator_non_trainable.trainable = False  # Configurar la copia como no entrenable\n",
    "\n",
    "# Crear el generador normalmente\n",
    "generator = build_generator(noise_dim, condition_dim, num_output_dim, cat_output_dim)\n",
    "\n",
    "# Construir el modelo combinado usando el discriminador no entrenable\n",
    "noise_input = Input(shape=(noise_dim,))\n",
    "condition_input = Input(shape=(condition_dim,))\n",
    "generated_strategy = generator([noise_input, condition_input])\n",
    "validity = discriminator_non_trainable([generated_strategy, condition_input])\n",
    "\n",
    "combined_model = Model([noise_input, condition_input], validity)\n",
    "optimizer_g = Adam(0.0002, 0.5)\n",
    "combined_model.compile(loss='binary_crossentropy', optimizer=optimizer_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931fe101-2d21-46fb-a548-28b718b83484",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae5beb-eb04-4092-ad32-74bad3bda10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos entrenables del discriminador: 6\n",
      "Pesos entrenables del generador: 8\n",
      "Pesos entrenables del modelo combinado: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "0 [Pérdida D: 0.6892, Precisión: 57.81%] [Pérdida G: 0.6729]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "1 [Pérdida D: 0.6987, Precisión: 47.79%] [Pérdida G: 0.6758]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "2 [Pérdida D: 0.6978, Precisión: 48.85%] [Pérdida G: 0.6740]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "3 [Pérdida D: 0.6969, Precisión: 49.94%] [Pérdida G: 0.6724]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "4 [Pérdida D: 0.6961, Precisión: 50.26%] [Pérdida G: 0.6725]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "5 [Pérdida D: 0.6955, Precisión: 49.51%] [Pérdida G: 0.6730]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "6 [Pérdida D: 0.6946, Precisión: 49.57%] [Pérdida G: 0.6740]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "7 [Pérdida D: 0.6933, Precisión: 50.23%] [Pérdida G: 0.6731]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "8 [Pérdida D: 0.6923, Precisión: 50.64%] [Pérdida G: 0.6738]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "9 [Pérdida D: 0.6910, Precisión: 51.62%] [Pérdida G: 0.6730]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "10 [Pérdida D: 0.6897, Precisión: 52.41%] [Pérdida G: 0.6717]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "11 [Pérdida D: 0.6889, Precisión: 53.07%] [Pérdida G: 0.6713]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "12 [Pérdida D: 0.6877, Precisión: 53.50%] [Pérdida G: 0.6706]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "13 [Pérdida D: 0.6867, Precisión: 54.32%] [Pérdida G: 0.6702]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "14 [Pérdida D: 0.6858, Precisión: 54.87%] [Pérdida G: 0.6707]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "15 [Pérdida D: 0.6845, Precisión: 56.25%] [Pérdida G: 0.6709]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "16 [Pérdida D: 0.6832, Precisión: 57.51%] [Pérdida G: 0.6702]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "17 [Pérdida D: 0.6820, Precisión: 58.32%] [Pérdida G: 0.6694]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "18 [Pérdida D: 0.6805, Precisión: 59.42%] [Pérdida G: 0.6685]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "19 [Pérdida D: 0.6793, Precisión: 60.25%] [Pérdida G: 0.6677]\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "\n",
    "print(\"Pesos entrenables del discriminador:\", len(discriminator.trainable_weights))\n",
    "print(\"Pesos entrenables del generador:\", len(generator.trainable_weights))\n",
    "print(\"Pesos entrenables del modelo combinado:\", len(combined_model.trainable_weights))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---------------------\n",
    "    #  Entrenar el discriminador\n",
    "    # ---------------------\n",
    "    idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "    real_strategies = y[idx]\n",
    "    conditions = X[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "    generated_strategies = generator.predict([noise, conditions])\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch([real_strategies, conditions], valid)\n",
    "    d_loss_fake = discriminator.train_on_batch([generated_strategies, conditions], fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Entrenar el generador\n",
    "    # ---------------------\n",
    "    g_loss = combined_model.train_on_batch([noise, conditions], valid)\n",
    "\n",
    "    print(f\"{epoch} [Pérdida D: {d_loss[0]:.4f}, Precisión: {d_loss[1]*100:.2f}%] [Pérdida G: {g_loss:.4f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d778d4-d0a3-4390-854b-64d3f5660f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Estrategia generada:\n",
      "Vuelta de parada: 35.68\n",
      "Duración del stint: 29.31\n",
      "Compuesto de neumático: HARD\n"
     ]
    }
   ],
   "source": [
    "# Generar una estrategia\n",
    "noise = np.random.normal(0, 1, (1, noise_dim))\n",
    "sample_condition = X[0:1]  # Condiciones para un circuito específico\n",
    "generated_strategy = generator.predict([noise, sample_condition])\n",
    "\n",
    "max_stops = 3\n",
    "\n",
    "# Interpretar la salida del generador\n",
    "num_stops = np.argmax(generated_strategy[:, :max_stops]) + 1  # Número de paradas\n",
    "\n",
    "lap_stops = generated_strategy[:, max_stops:max_stops + num_stops]  # Vueltas de parada escaladas\n",
    "lap_stops = lap_stops.astype(int)  # Redondear a vueltas enteras\n",
    "\n",
    "num_tire_types = races_info['Compound'].nunique()\n",
    "\n",
    "tire_types = []\n",
    "start_idx = max_stops + num_stops\n",
    "for i in range(num_stops):\n",
    "    tire_type_index = np.argmax(generated_strategy[:, start_idx + i*num_tire_types:start_idx + (i+1)*num_tire_types])\n",
    "    tire_type = encoder_tire_types.categories_[0][tire_type_index]  # Mapeo del tipo de neumático\n",
    "    tire_types.append(tire_type)\n",
    "\n",
    "# Imprimir la estrategia generada\n",
    "print(\"Número de paradas:\", num_stops)\n",
    "for i in range(num_stops):\n",
    "    print(f\"Parada {i+1}:\")\n",
    "    print(f\" - Vuelta de parada: {lap_stops[0][i]}\")\n",
    "    print(f\" - Tipo de neumático: {tire_types[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2c320-1a4f-46ce-9a71-0ebf30998688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fa39a-d101-4945-a1fa-5d82e4cfc884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231a003-98f2-4799-a69a-c77ebbbd322b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
